{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DCGAN on MNIST using Keras\n",
    "Author: Rowel Atienza\n",
    "Project: https://github.com/roatienza/Deep-Learning-Experiments\n",
    "Dependencies: tensorflow 1.0 and keras 2.0\n",
    "Usage: python3 dcgan_mnist.py\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(\"sample_2019-11-13-16-10.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.5,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0.5,  1. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0.5,  1. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       ...,\n",
       "       [ 9.5, 10. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [10. , 10.5,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [10.5, 11. ,  0. , ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 20, 130)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_151 (Dense)            (None, 160)               16160     \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "reshape_58 (Reshape)         (None, 5, 32, 1)          0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 5, 32, 1)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_59 (UpSampling (None, 10, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_113 (Conv2D (None, 10, 64, 128)       3328      \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 10, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 10, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_60 (UpSampling (None, 20, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_114 (Conv2D (None, 20, 128, 64)       204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 20, 128, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 20, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_115 (Conv2D (None, 20, 128, 32)       51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 20, 128, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 20, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_116 (Conv2D (None, 20, 128, 1)        801       \n",
      "_________________________________________________________________\n",
      "softmax_13 (Softmax)         (None, 20, 128, 1)        0         \n",
      "=================================================================\n",
      "Total params: 277,921\n",
      "Trainable params: 277,153\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_152 (Dense)            (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)   (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "reshape_59 (Reshape)         (None, 20, 2, 1)          0         \n",
      "=================================================================\n",
      "Total params: 3,600\n",
      "Trainable params: 3,440\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from keras.layers import Input, Dense, Reshape, Dropout, CuDNNLSTM, Bidirectional, concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers import Softmax\n",
    "\n",
    "def get_notes():\n",
    "    notes=np.load('sample_2019-11-13-16-10.npy')\n",
    "    return notes\n",
    "\n",
    "notes = get_notes()\n",
    "print(notes.shape)\n",
    "\n",
    "def generator1():\n",
    "    model = Sequential()\n",
    "    dropout = 0.4\n",
    "    cols = 32\n",
    "    rows = 5\n",
    "    depth = 64 + 64 + 64 + 64\n",
    "    # Out: 20 X 130\n",
    "    model.add(Dense(rows*cols, input_dim=100))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((rows, cols, 1)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "    model.add(Softmax(axis=1))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "generator1 = generator1()\n",
    "\n",
    "def generatorForStartAndEnd():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=100))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(20))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(40))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Reshape((20,2,1)))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "generator2 = generatorForStartAndEnd()\n",
    "\n",
    "generator_concat = concatenate([generator1.output, generator2.output], axis=-2)\n",
    "generator = Dense(1)(model_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise1 = np.random.uniform(-1.0, 1.0, size=[50, 100])\n",
    "noise2 = np.random.uniform(-1.0, 1.0, size=[1000, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'dense_132_input:0' shape=(?, 100) dtype=float32>,\n",
       " <tf.Tensor 'dense_133_input:0' shape=(?, 100) dtype=float32>]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generator.predict([noise1, noise2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator\n",
    "num_nodes = 128\n",
    "dropout_rate = 0.2\n",
    "\n",
    "data_inputs = Input(shape=(20, 130, 1))\n",
    "dense1 = Dense(num_nodes, activation='relu')(data_inputs)\n",
    "dropout1 = Dropout(dropout_rate)(dense1)\n",
    "batchNorm1 = BatchNormalization()(dropout1)\n",
    "\n",
    "dense2 = Dense(num_nodes, activation='relu')(batchNorm1)\n",
    "dropout2 = Dropout(dropout_rate)(dense2)\n",
    "batchNorm2 = BatchNormalization()(dropout2)\n",
    "\n",
    "true_fake_output = Dense(2, activation='sigmoid')(batchNorm2)\n",
    "\n",
    "discriminator = Model(inputs=[data_inputs], outputs=[true_fake_output])\n",
    "\n",
    "discriminator.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_155/BiasAdd:0' shape=(?, 20, 130, 1) dtype=float32>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_input = Input(shape=(100,))\n",
    "x = generator()\n",
    "gan_output= discriminator(x)\n",
    "gan= Model(inputs=gan_input, outputs=gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.engine.training.Model object at 0x1cba229a20>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-bb1f26214485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerator1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgenerator_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0madversarial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerator1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0madversarial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m                                  \u001b[0;34m'the output of a Keras `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                                  \u001b[0;34m'(thus holding past layer metadata). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                                  'Found: ' + str(x))\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.engine.training.Model object at 0x1cba229a20>"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "generator_concat = concatenate([generator1.output, generator2.output], axis=-2)\n",
    "generator_concat = Dense(1)(model_concat)\n",
    "adversarial = Model(inputs=[generator1.input, generator2.input], outputs=discriminator)\n",
    "adversarial.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_model(num_elements):\n",
    "    \n",
    "    inputs = Input(shape=(num_elements,))\n",
    "    dense1 = Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    # (Wâˆ’F+2P)/S+1\n",
    "    def discriminator(self):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        self.D = Sequential()\n",
    "        depth = 64\n",
    "        dropout = 0.4\n",
    "        # In: 28 x 28 x 1, depth = 1\n",
    "        # Out: 14 x 14 x 1, depth=64\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n",
    "            padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        self.G = Sequential()\n",
    "        dropout = 0.4\n",
    "        depth = 64+64+64+64\n",
    "        dim = 7\n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(Reshape((dim, dim, depth)))\n",
    "        self.G.add(Dropout(dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.AM\n",
    "\n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "\n",
    "        self.x_train = input_data.read_data_sets(\"mnist\",\\\n",
    "        \tone_hot=True).train.images\n",
    "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n",
    "        \tself.img_cols, 1).astype(np.float32)\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
