{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from keras.layers import Input, Dense, Reshape, Dropout, CuDNNLSTM, Bidirectional, concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers import Softmax\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load(\"sample_2019-11-13-16-10.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0. ,  0.5,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0.5,  1. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [ 0.5,  1. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       ...,\n",
       "       [ 9.5, 10. ,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [10. , 10.5,  0. , ...,  0. ,  0. ,  0. ],\n",
       "       [10.5, 11. ,  0. , ...,  0. ,  0. ,  0. ]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 20, 130)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 160)               16160     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 160)               640       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 5, 32, 1)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 32, 1)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 10, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 10, 64, 128)       3328      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 20, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 20, 128, 64)       204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 20, 128, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 20, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 20, 128, 32)       51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 20, 128, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 20, 128, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 20, 128, 1)        801       \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 20, 128, 1)        0         \n",
      "=================================================================\n",
      "Total params: 277,921\n",
      "Trainable params: 277,153\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 20, 2, 1)          0         \n",
      "=================================================================\n",
      "Total params: 3,600\n",
      "Trainable params: 3,440\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_notes():\n",
    "    notes=np.load('sample_2019-11-13-16-10.npy')\n",
    "    return notes\n",
    "\n",
    "notes = get_notes()\n",
    "print(notes.shape)\n",
    "\n",
    "def make_pitch_generator():\n",
    "    model = Sequential()\n",
    "    dropout = 0.4\n",
    "    cols = 32\n",
    "    rows = 5\n",
    "    depth = 64 + 64 + 64 + 64\n",
    "    # Out: 20 X 130\n",
    "    model.add(Dense(rows*cols, input_dim=100))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((rows, cols, 1)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "    model.add(Softmax(axis=1))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "generator_pitch = make_pitch_generator()\n",
    "\n",
    "def make_generator_start_end():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=100))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(20))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(40))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Reshape((20,2,1)))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "generator_start_end = make_generator_start_end()\n",
    "\n",
    "generator_concat = concatenate([generator_pitch.output, generator_start_end.output], axis=-2)\n",
    "generator_concat = Dense(1)(generator_concat)\n",
    "generator = Model(inputs=[generator_pitch.input, generator_start_end.input], outputs=generator_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_10/BiasAdd:0' shape=(?, 20, 130, 1) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-1.0, 1.0, size=[50, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generator.predict([noise, noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0803487999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.05401744 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0719454"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(result[0][0:20, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate noise\n",
    "n_samples = 100\n",
    "noise_length = 128\n",
    "noise = np.random.uniform(-1.0, 1.0, size=[n_samples, noise_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator\n",
    "num_nodes = 128\n",
    "dropout_rate = 0.2\n",
    "\n",
    "random_inputs = Input(shape=(noise_length,))\n",
    "dense1 = Dense(num_nodes, activation='relu')(random_inputs)\n",
    "dropout1 = Dropout(dropout_rate)(dense1)\n",
    "batchNorm1 = BatchNormalization()(dropout1)\n",
    "dense2 = Dense(num_nodes, activation='relu')(batchNorm1)\n",
    "dropout2 = Dropout(dropout_rate)(dense2)\n",
    "batchNorm2 = BatchNormalization()(dropout2)\n",
    "\n",
    "pitch = Dense(20 * 128)(batchNorm2)\n",
    "duration = Dense(20 * 2)(batchNorm2)\n",
    "\n",
    "pitch_reshaped = Reshape((20, 128))(pitch)\n",
    "duration_reshaped = Reshape((20, 2))(duration)\n",
    "\n",
    "pitch_output = Softmax(axis=-1)(pitch_reshaped)\n",
    "duration_output = Dense(2, activation='relu', name='duration')(duration_reshaped)\n",
    "output_concat = concatenate([duration_output, pitch_output])\n",
    "\n",
    "generator = Model(inputs=random_inputs, outputs=output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.15645309, 0.        , 0.00710962, ..., 0.0073821 ,\n",
       "         0.00714432, 0.00792802],\n",
       "        [0.18877085, 0.19557388, 0.00731536, ..., 0.00807713,\n",
       "         0.00728555, 0.00799938],\n",
       "        [0.25478068, 0.10027927, 0.00714836, ..., 0.00811918,\n",
       "         0.00765923, 0.00834646],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.00692928, ..., 0.00879381,\n",
       "         0.00786162, 0.00867419],\n",
       "        [0.07986229, 0.09001254, 0.00827463, ..., 0.00678803,\n",
       "         0.00696803, 0.00791797],\n",
       "        [0.        , 0.15378585, 0.00692377, ..., 0.00842176,\n",
       "         0.00723738, 0.00742429]],\n",
       "\n",
       "       [[0.14973535, 0.        , 0.00637885, ..., 0.00735982,\n",
       "         0.00789291, 0.00798584],\n",
       "        [0.5437106 , 0.18771492, 0.00795301, ..., 0.00752186,\n",
       "         0.00752698, 0.0079512 ],\n",
       "        [0.10416038, 0.09374883, 0.00750843, ..., 0.00789902,\n",
       "         0.00814482, 0.00773575],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.00704564, ..., 0.0084009 ,\n",
       "         0.00738068, 0.00742434],\n",
       "        [0.        , 0.13133526, 0.00787353, ..., 0.00722491,\n",
       "         0.00793181, 0.00781467],\n",
       "        [0.22415039, 0.0791896 , 0.00739339, ..., 0.00753129,\n",
       "         0.00622353, 0.00818086]],\n",
       "\n",
       "       [[0.16184756, 0.        , 0.00745913, ..., 0.00782312,\n",
       "         0.00812412, 0.00619001],\n",
       "        [0.        , 0.05884129, 0.00779641, ..., 0.00780815,\n",
       "         0.00739801, 0.00780975],\n",
       "        [0.44381243, 0.14982468, 0.00749573, ..., 0.00801872,\n",
       "         0.00742221, 0.00768011],\n",
       "        ...,\n",
       "        [0.17417207, 0.0601205 , 0.00713747, ..., 0.00965515,\n",
       "         0.00862472, 0.0082206 ],\n",
       "        [0.1979637 , 0.0688194 , 0.00857065, ..., 0.00748269,\n",
       "         0.0069785 , 0.00830215],\n",
       "        [0.17322998, 0.03757884, 0.00756057, ..., 0.00733847,\n",
       "         0.00700929, 0.00758083]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.46763107, 0.        , 0.00670394, ..., 0.00710783,\n",
       "         0.00881588, 0.00723986],\n",
       "        [0.29365912, 0.        , 0.00671483, ..., 0.00692167,\n",
       "         0.00747562, 0.0094716 ],\n",
       "        [0.38053218, 0.        , 0.00794988, ..., 0.00694531,\n",
       "         0.00723898, 0.00750839],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.00715674, ..., 0.00875323,\n",
       "         0.00739087, 0.00780601],\n",
       "        [0.        , 0.14285755, 0.00896529, ..., 0.00684706,\n",
       "         0.00785196, 0.00856223],\n",
       "        [0.15971948, 0.1618634 , 0.00769825, ..., 0.00780562,\n",
       "         0.00754071, 0.00674149]],\n",
       "\n",
       "       [[0.2177681 , 0.02414833, 0.00748012, ..., 0.00816281,\n",
       "         0.00796151, 0.0079192 ],\n",
       "        [0.27989182, 0.04745178, 0.0074285 , ..., 0.00731601,\n",
       "         0.00687628, 0.00701737],\n",
       "        [0.21257369, 0.16077077, 0.00772304, ..., 0.00812322,\n",
       "         0.00769764, 0.00730055],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.00696022, ..., 0.00805807,\n",
       "         0.00716178, 0.00793615],\n",
       "        [0.3529785 , 0.        , 0.00896751, ..., 0.00718036,\n",
       "         0.00786178, 0.00766929],\n",
       "        [0.00075262, 0.04991277, 0.00804718, ..., 0.00831425,\n",
       "         0.00708887, 0.00879167]],\n",
       "\n",
       "       [[0.1387335 , 0.        , 0.00775162, ..., 0.00777523,\n",
       "         0.00870239, 0.00731362],\n",
       "        [0.22213675, 0.01154585, 0.00717175, ..., 0.00778179,\n",
       "         0.00824892, 0.00828225],\n",
       "        [0.33345896, 0.1292595 , 0.00745078, ..., 0.00799582,\n",
       "         0.00811023, 0.00783527],\n",
       "        ...,\n",
       "        [0.11318645, 0.        , 0.00714304, ..., 0.00877385,\n",
       "         0.00746919, 0.00871135],\n",
       "        [0.01312194, 0.        , 0.00879128, ..., 0.00774692,\n",
       "         0.00813849, 0.00928945],\n",
       "        [0.16855846, 0.17211457, 0.00780097, ..., 0.00884308,\n",
       "         0.00827084, 0.00842379]]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator\n",
    "num_nodes = 128\n",
    "dropout_rate = 0.2\n",
    "\n",
    "data_inputs = Input(shape=(20, 130, 1))\n",
    "dense1 = Dense(num_nodes, activation='relu')(data_inputs)\n",
    "dropout1 = Dropout(dropout_rate)(dense1)\n",
    "batchNorm1 = BatchNormalization()(dropout1)\n",
    "\n",
    "dense2 = Dense(num_nodes, activation='relu')(batchNorm1)\n",
    "dropout2 = Dropout(dropout_rate)(dense2)\n",
    "batchNorm2 = BatchNormalization()(dropout2)\n",
    "\n",
    "true_fake_output = Dense(2, activation='sigmoid')(batchNorm2)\n",
    "\n",
    "discriminator = Model(inputs=[data_inputs], outputs=[true_fake_output])\n",
    "\n",
    "discriminator.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_155/BiasAdd:0' shape=(?, 20, 130, 1) dtype=float32>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_input = Input(shape=(100,))\n",
    "x = generator()\n",
    "gan_output= discriminator(x)\n",
    "gan= Model(inputs=gan_input, outputs=gan_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.engine.training.Model object at 0x1cba229a20>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-258-bb1f26214485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerator1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgenerator_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_concat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0madversarial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerator1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0madversarial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    186\u001b[0m                                  \u001b[0;34m'the output of a Keras `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                                  \u001b[0;34m'(thus holding past layer metadata). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                                  'Found: ' + str(x))\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.engine.training.Model object at 0x1cba229a20>"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "generator_concat = concatenate([generator1.output, generator2.output], axis=-2)\n",
    "generator_concat = Dense(1)(model_concat)\n",
    "adversarial = Model(inputs=[generator1.input, generator2.input], outputs=discriminator)\n",
    "adversarial.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator_model(num_elements):\n",
    "    \n",
    "    inputs = Input(shape=(num_elements,))\n",
    "    dense1 = Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=28, img_cols=28, channel=1):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    # (Wâˆ’F+2P)/S+1\n",
    "    def discriminator(self):\n",
    "        if self.D:\n",
    "            return self.D\n",
    "        self.D = Sequential()\n",
    "        depth = 64\n",
    "        dropout = 0.4\n",
    "        # In: 28 x 28 x 1, depth = 1\n",
    "        # Out: 14 x 14 x 1, depth=64\n",
    "        input_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\\\n",
    "            padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*2, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*4, 5, strides=2, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        self.D.add(Conv2D(depth*8, 5, strides=1, padding='same'))\n",
    "        self.D.add(LeakyReLU(alpha=0.2))\n",
    "        self.D.add(Dropout(dropout))\n",
    "\n",
    "        # Out: 1-dim probability\n",
    "        self.D.add(Flatten())\n",
    "        self.D.add(Dense(1))\n",
    "        self.D.add(Activation('sigmoid'))\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "\n",
    "    def generator(self):\n",
    "        if self.G:\n",
    "            return self.G\n",
    "        self.G = Sequential()\n",
    "        dropout = 0.4\n",
    "        depth = 64+64+64+64\n",
    "        dim = 7\n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        self.G.add(Dense(dim*dim*depth, input_dim=100))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "        self.G.add(Reshape((dim, dim, depth)))\n",
    "        self.G.add(Dropout(dropout))\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(UpSampling2D())\n",
    "        self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))\n",
    "        self.G.add(BatchNormalization(momentum=0.9))\n",
    "        self.G.add(Activation('relu'))\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        self.G.add(Conv2DTranspose(1, 5, padding='same'))\n",
    "        self.G.add(Activation('sigmoid'))\n",
    "        self.G.summary()\n",
    "        return self.G\n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        optimizer = RMSprop(lr=0.0002, decay=6e-8)\n",
    "        self.DM = Sequential()\n",
    "        self.DM.add(self.discriminator())\n",
    "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        optimizer = RMSprop(lr=0.0001, decay=3e-8)\n",
    "        self.AM = Sequential()\n",
    "        self.AM.add(self.generator())\n",
    "        self.AM.add(self.discriminator())\n",
    "        self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
    "            metrics=['accuracy'])\n",
    "        return self.AM\n",
    "\n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channel = 1\n",
    "\n",
    "        self.x_train = input_data.read_data_sets(\"mnist\",\\\n",
    "        \tone_hot=True).train.images\n",
    "        self.x_train = self.x_train.reshape(-1, self.img_rows,\\\n",
    "        \tself.img_cols, 1).astype(np.float32)\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "        for i in range(train_steps):\n",
    "            images_train = self.x_train[np.random.randint(0,\n",
    "                self.x_train.shape[0], size=batch_size), :, :, :]\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            images_fake = self.generator.predict(noise)\n",
    "            x = np.concatenate((images_train, images_fake))\n",
    "            y = np.ones([2*batch_size, 1])\n",
    "            y[batch_size:, :] = 0\n",
    "            d_loss = self.discriminator.train_on_batch(x, y)\n",
    "\n",
    "            y = np.ones([batch_size, 1])\n",
    "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "            a_loss = self.adversarial.train_on_batch(noise, y)\n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (i, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f, acc: %f]\" % (log_mesg, a_loss[0], a_loss[1])\n",
    "            print(log_mesg)\n",
    "            if save_interval>0:\n",
    "                if (i+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(i+1))\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=16, noise=None, step=0):\n",
    "        filename = 'mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"mnist_%d.png\" % step\n",
    "            images = self.generator.predict(noise)\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
