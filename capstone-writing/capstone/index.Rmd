---
author: 'Terry Wang, Rima Mittal, Joshua Goldberg'
date: 'March, 2020'
institution: 'University of Chicago'
division: 'Graham School'
advisor: 'Yuri Balasanov'
altadvisor: ''
department: 'Continuing Liberal and Professional Studies'
degree: 'Master of Science in Analytics'
title: 'Music Generator'
knit: "bookdown::render_book"
site: bookdown::bookdown_site
output: 
  phoenixdown::capstone_pdf: default
#  phoenixdown::capstone_gitbook: default
#  phoenixdown::capstone_word: default
#  phoenixdown::capstone_epub: default
#
# If you are creating a PDF you'll need to write your preliminary content as well as define some other parameters below.
abstract: | 
  `r if(knitr:::is_latex_output()) paste(readLines("00--abstract.Rmd"), collapse = '\n  ')` 
executive: |  
  `r if(knitr:::is_latex_output()) paste(readLines("00--executive-summary.Rmd"), collapse = '\n  ')` 
#
# Longer preliminary content, like the Abstract and Executive Summary above, is best organized in seperate files.
# The inline r function is used above to paste the contents of those files, instead of requiring you one to type 
# lengthy text directly into the yaml header. For shorter messages, typing directly into the YAML is easier. See below.
# VERY IMPORTANT: A tab indent is needed on the line following the |.
#
# preface: |
 # A preface is OPTIONAL. Use a preface if you want to explain your interest in the report topic and include anything about your experience that readers should keep in mind. If you would rather not include a preface, comment it out or delete it from the YAML header of the index.Rmd file.

#acknowledgements: |
#  I want to thank a few people.
#dedication: |
#  You can have a dedication here if you wish.
#
# Download your specific bibliography database file, place it in the "bib" folder, and refer to it in the line below
bibliography: bib/thesis.bib
#
# To change your Citation Style Language file, you can do so below. Though the default is apa style.
csl: csl/apa.csl
lot: true
lof: true
#
# Add a "#" at the beginning of the following line if you'd like remove space between parapgraphs.
space_between_paragraphs: true
#
# Dimensions below correspond to University of Chicago Masters of Science in Analytics requirements.
geometry: "left=3.8cm, right=2.5cm, top=2.5cm, bottom=2.5cm"
#
  #header-includes:
#- \usepackage{tikz}
---



<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Preface for example, simply delete lines 32-33 above or add a "#"" before them to comment out.  If you have other LaTeX packages you would like to include, delete the # before header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file enclose it in a block like this:
-->

<!--

If you receive a duplicate label error after knitting, delete the extra .Rmd file and then knit again.
-->

<!-- You'll need to include the order that you'd like Rmd files to appear in the _bookdown.yml file for PDF files and also delete the # before rmd_files: there. Do not include 00(two-hyphens)prelim.Rmd,  00(two-hyphens)abstract.Rmd and 00(two-hyphens)executive summary.Rmdsince they are handled in the YAML above differently for the PDF version.
-->

<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." You can also use {-} for no numbers on chapters, which is the standard for each section.
-->

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(knitr)
```

# Introduction {.unnumbered}

We built a deep learning model to help individuals generate interesting music ideas. The model is a GAN-based generator. The data used to train the generator are 130,000 midi files across many different genres of music.
        
## Problem Statement {.unnumbered}

In 1950s, experimental music composers wrote music using randomized statistical modelling. In 1990s, David Bowie built the Verbasizer, which implemented a random re-ordering of group of words and sentences to produce potentially significant lyrical combinations. Nowadays, there is an entire industry built around AI generated music including Flow Machines, IBM Watson Beat and Googleâ€™s NSynth. 

Our purpose is to build an effective platform to help artists in their creative process and assist them in music composition. Note that artists do not have to be professionally designated. Any individual interested in creating music should find the platform useful and empowering.  The first concrete step we need to take to achieve that goal is to build a music generation model that is able to generate music that is similar to what a human would compose in the style of music the model is trained on.


## Research Purpose {.unnumbered}

The purpose of this project is to develop a deep learning based music generator (instrumental music) which has a good understanding of the language of music and is able to generate human-like outputs, ultimately helping musicians and non-musicians alike to develop and refine musical ideas, and facilitate them in the music composition process. We divided the project into two parts, Generation and Validation. 

By doing this iteratively, the weights and parameters of the model will hopefully converge to a point at which the music generated is satisfactory to the user, who can use the output of the model, or save the weights for future use.  In a sense, we are democratizing deep learning to non-technical users wishing to generate new music ideas in a novel way. Moreover, we expect the algorithmic process to able to explore more music combinations than any individual, and thus provide a more holistic and creative approach to music creation.

## Variables and Scope {.unnumbered}

Our data consists of 130,000 midi files curated by a Reddit user, with a size of 3.65GB uncompressed. The collection has a great amount of variety representing all major genres in classical, jazz, metal, pop, etc. These midi files can be parsed by python packages such as midi and music21 into numpy arrays that preserves the note duration information, and our model will be trained on them.
