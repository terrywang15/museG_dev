<!--
This is for including Chapter 1.  Notice that it's also good practice to name your chunk.  This will help you debug potential issues as you knit.  The chunk above is called intro and the one below is called background.  Feel free to change the name of the Rmd file as you wish, but don't forget to change it here from 01-background.Rmd.
-->

<!--
The {#background} text after the chapter declaration will allow us to link throughout the document back to the beginning of of the background section.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

# Background {#background .unnumbered}

We propose the application of Deep Learning models to help individuals generate interesting music ideas with the goal of aiding musicians to use these computer-generated musical ideas to enhance their music writing process. Our model focuses on generating melody instead of the sound. We use midi files consisting of music notes, as training data. In addition, we explore a unique model structure where the time dependency inherent in music is not explicitly given to the model but is inferred by the model through the deep neural network structure. Despite this, we have observed that the model was able to learn time-dependent musical structure, such as the pre-dominant to dominant to tonic chord progression. 

We note that the model exhibits certain unconventional behavior. This can be attributed to the model using a different perspective to create music compared to humans. This behavior may be useful in inspiring musicians to create new music.

**Historical Background**

in 1957, A 17 seconds long melody named "The Silver Scale" was the first ever music generated by computer [@silver_scale] using synthesizers. Around the same time, musicians and statisticians started to attempt to decode the language of music using statistical methods. Some of the very early algorithms used stochastic Markov Chain models for generation and rule filtering as well as more advanced Bayesian models [@temperley2007]. In 1990s, David Bowie built the Verbasizer, which implemented a random re-ordering of groups of words and sentences to produce potentially significant lyrical combinations (provide an example of this).

Since then, computer music has been gaining a lot of public attention. In present time, there is an entire industry built around AI generated music including Flow Machines [@flow_machines], IBM Watson Beat [@watson] and Googleâ€™s NSynth [@nsynth]. 

\newpage
