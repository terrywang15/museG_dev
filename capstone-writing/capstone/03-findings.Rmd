# Findings {#findings .unnumbered}

We divide our findings into two separate sections: GAN Training and Assessment of Model Output. 

## GAN Training {#findings-gan_training .unnumbered}
 
GAN models are notoriously hard to train properly. During training of our model, we encountered numerous issues which we have had varying degrees of success in addressing. The main issues are:

1. Error balancing. In many cases, the errors from the discriminator and generator often collapse to 0 or become extremely large.
2. Mode collapse. Model learns to generate one kind of output that is able to fool the discriminator despite random input.

We will be referring to discriminator and generator losses in the following section. To clarify, discriminator loss is loss from training the discriminator specifically and generator loss is the loss from training the adversarial model.

### Error Balancing {.unnumbered}

Using the data we collected from the training process, we find that the GAN training can be summarized into three distinctive stages:

1. The initial chaos. The generator and discriminator are trying to balance each other out and the error can vary drastically from epoch to epoch and either the discriminator or generator loss can be much larger than the other. It often settles into a more balanced stage, but this is not a given as we observe some models being unable to get past this initial stage.
2. The stable equilibrium. The model enters into a stable stage characterized by similar magnitude of losses between discriminator and generator and across different epochs. Judging from the quality of the output, it is during this period when the model learned the most from training data and generated the most musical samples.
3. The final collapse. This stage is characterized by a steady increase in loss magnitude in one of or both the generator and the discriminator, until the losses of either model collapsing to 0. There are even rare cases where both the discriminator and generator losses go down to 0.

In the following plot of one of the training sessions we can observe these three distinctive stages:

**Insert loss graph**



### Mode Collapse {.unnumbered}

Mode collapse is a common problem for GAN models **citation needed**. 

```{r summary}
kable(summary(ToothGrowth), align = "r", caption = "Summary of ToothGrowth data",
      format = "latex", longtable = TRUE)
```

Table \@ref(tab:summary) above contains summary statistics of the _Tooth Growth_ data.

While the code is not displayed to create the graph below (`echo=FALSE`), it is displayed in the Appendix by referencing the `boxplot` chunk name..

```{r boxplot, echo=FALSE, warning=FALSE,  message=FALSE, fig.cap="Avg. length by  supplement and dose", fig.width=6}
data(ToothGrowth)
colnames(ToothGrowth) <- c("length", "supplement", "dose")
ToothGrowth$dose <- as.factor(ToothGrowth$dose)

groupedTooth <- aggregate(ToothGrowth, by=ToothGrowth[,2:3], FUN=mean)[,1:3]

library(ggplot2)
 ggplot(ToothGrowth, aes(x = supplement, y = length)) + 
                     geom_boxplot(aes(fill=supplement)) + 
                     facet_wrap(~dose) + 
                     guides(colour = guide_legend("Color = Supplement")) + 
                     labs(x="Orange Juice or Vitamin C, grouped by dose", 
                          y="Odontoblast Growth (microns)")  +
                     theme_bw()
```

Figure \@ref(fig:boxplot) was created with the `ggplot2` package. We can visually compare the average tooth growth by `supplement` and `dose`.

## Modeling results  {.unnumbered}

First, use a `t.test()` to test _if_ dosage leads to growth of incisor length. From the results below, it appears every test rejects the null hypothesis.

```{r t-test}
test1 <- t.test(length ~ dose, ToothGrowth, dose %in% c(0.5,1)) 
test2 <- t.test(length ~ dose, ToothGrowth, dose %in% c(0.5,2))
test3 <- t.test(length ~ dose, ToothGrowth, dose %in% c(1,2)) 

testAgg <- data.frame(Name = c("Test 0.5-1", "Test 0.5-2", "Test 1-2"),
                  Method = c(test1$method, test2$method, test3$method), 
               Pvalue = c(test1$p.value, test2$p.value, test3$p.value), 
          Tstat = c(test1$statistic, test2$statistic, test3$statistic))

kable(testAgg, digit = 7, align = "r", caption = "t-test results", 
      format = "latex", longtable = TRUE)
```

Table \@ref(tab:t-test)

## Results of model performance and validation  {.unnumbered}

Next, subset the `ToothGrowth` data into seperate data sets defined by supplement dose of 0.5, 1, and 2 mg. This allow us to controlling for dose increases of _economic_ significance.

Subset tooth data into a separate `data.frame` for each dosage level. Then Execute the `t.test()` function for the dosage of 0.5 mg and display the results. 

```{r}
dose05 <- ToothGrowth[ToothGrowth$dose == 0.5, ] 
 dose1 <- ToothGrowth[ToothGrowth$dose == 1, ]
 dose2 <- ToothGrowth[ToothGrowth$dose == 2, ]

 test4 <- t.test(length ~ supplement, data = dose05)
 test5 <- t.test(length ~ supplement, data = dose1)
 test6 <- t.test(length ~ supplement, data = dose2)
```

Place the results of the analysis directly into your content with ***inline code*** functions:

With a very low p-value of `r round(test4$p.value, 4)` and a corresponding t-statistic of `r round(test4$statistic, 4)`, it appears that at low doses, _Orange Juice_ is the preferable delivery mechanism to _Vitamin C_ for Ascorbic Acid delivery.

The p-value and t-statistic above have been directly extracted from the model object and printed inline. using the 'r foo' syntax with quotes(') replaced by back-ticks (`).




